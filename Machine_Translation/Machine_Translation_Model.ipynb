{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2fGJ_1qXRxu"
      },
      "source": [
        "Used seq2seq encoder-decoder architecture, which uses LSTM (Long Short Term Memory), encodes the input hindi sequence into a single vector. This vector is then sent into the decoder neural network, which produces the English translation sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSuJ-9X_qk1b"
      },
      "source": [
        "#Imports "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import random\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from pprint import pprint\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "-Tfx8YlRRgQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "S-Ycz13hbUbC",
        "outputId": "365889b3-826b-41b4-cae7-e10f3733a197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Seeding for reproducible results everytime\\nSEED = 777\\n\\nrandom.seed(SEED)\\nnp.random.seed(SEED)\\ntorch.manual_seed(SEED)\\ntorch.cuda.manual_seed(SEED)\\ntorch.backends.cudnn.deterministic = True'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0 --quiet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VZEieMrL2NP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from indicnlp.tokenize import indic_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrNraUABrDq2",
        "outputId": "21829ae7-1193-4016-8f27-be29d3d5f95a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-11 14:19:51.844968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7Da1d8Pb-p4"
      },
      "outputs": [],
      "source": [
        "nlp_en = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSNo_alcLqHy",
        "outputId": "a2249279-64ee-4e98-b29f-d8d6899637c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.91-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from indic-nlp-library) (1.22.4)\n",
            "Collecting sphinx-argparse\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from indic-nlp-library) (1.4.4)\n",
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.2.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->indic-nlp-library) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from sphinx-argparse->indic-nlp-library) (3.5.4)\n",
            "Collecting sphinxcontrib-jquery!=3.0.0,>=2.0.0\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docutils<0.19 in /usr/local/lib/python3.9/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (0.16)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->indic-nlp-library) (1.16.0)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.27.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.4)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.12.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.14.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (67.6.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2022.12.7)\n",
            "Installing collected packages: morfessor, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.91 morfessor-2.0.6 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.2.0 sphinxcontrib-jquery-4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install indic-nlp-library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG66Y0FWLurH",
        "outputId": "aad5a533-44a3-491c-fc0b-1a44c39fd7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp39-cp39-linux_x86_64.whl (1982.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m860.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp39-cp39-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp39-cp39-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch==1.8.0+cu111) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.8.0+cu111) (4.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.9.0+cu111) (8.4.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.0.1+cu118\n",
            "    Uninstalling torchaudio-2.0.1+cu118:\n",
            "      Successfully uninstalled torchaudio-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5Ku1mTuLx7R",
        "outputId": "aa841892-16ef-4d7e-c629-ceb0a1a70232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.9/dist-packages (0.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6.0) (1.8.0+cu111)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6.0) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6.0) (2.27.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from torchtext==0.6.0) (0.1.97)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpcUm_eqL_qT",
        "outputId": "74e509b6-58ea-4e36-9d72-33b6090b0d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1362, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 1362 (delta 111), reused 98 (delta 93), pack-reused 1219\u001b[K\n",
            "Receiving objects: 100% (1362/1362), 9.56 MiB | 12.04 MiB/s, done.\n",
            "Resolving deltas: 100% (721/721), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PNs_RkaL_to",
        "outputId": "e95b6bec-4dbb-469e-b7cd-73b1802096c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/13)\u001b[K\rremote: Counting objects:  15% (2/13)\u001b[K\rremote: Counting objects:  23% (3/13)\u001b[K\rremote: Counting objects:  30% (4/13)\u001b[K\rremote: Counting objects:  38% (5/13)\u001b[K\rremote: Counting objects:  46% (6/13)\u001b[K\rremote: Counting objects:  53% (7/13)\u001b[K\rremote: Counting objects:  61% (8/13)\u001b[K\rremote: Counting objects:  69% (9/13)\u001b[K\rremote: Counting objects:  76% (10/13)\u001b[K\rremote: Counting objects:  84% (11/13)\u001b[K\rremote: Counting objects:  92% (12/13)\u001b[K\rremote: Counting objects: 100% (13/13)\u001b[K\rremote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (139/139), 149.77 MiB | 31.63 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Updating files: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4Ofb0tLMZT5",
        "outputId": "2209a3f7-4b7b-4f78-a6d4-d42fb41a77a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Morfessor in /usr/local/lib/python3.9/dist-packages (2.0.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install Morfessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4llEtL2mMbk2"
      },
      "outputs": [],
      "source": [
        "INDIC_NLP_LIB_HOME=r\"/content/indic_nlp_library\"\n",
        "INDIC_NLP_RESOURCES=\"/content/indic_nlp_resources\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F7KOLTsMdz9"
      },
      "outputs": [],
      "source": [
        "from indicnlp.tokenize import sentence_tokenize\n",
        "from indicnlp.tokenize import indic_tokenize  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plmENjcBKtzx"
      },
      "source": [
        "# DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK0LkzwnKqkh",
        "outputId": "4c1d7e50-b23a-4c5e-925c-75a1f5d7066e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHBCRDc1K18z"
      },
      "outputs": [],
      "source": [
        "# base directory path, CS779_NLP_COMP/1_MT\n",
        "base_dir = '/content/drive/MyDrive/CS779_NLP_COMP/1_MT/'\n",
        "\n",
        "# Access files, /input_data\n",
        "folder_name = 'input_data'\n",
        "\n",
        "# file_path\n",
        "file_path = base_dir + folder_name + '/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPOy2dmvOXaZ",
        "outputId": "b1745741-7f9d-4806-884d-5cddaa482949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 11 14:19:22 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-processing (Using torchtext and Spacy)"
      ],
      "metadata": {
        "id": "84RYRxGZR29c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z2N556lfK1_b",
        "outputId": "3279d4a9-816b-4a76-9752-2de03e4083ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0  \\\n",
              "0  and deliver us by Thy mercy from the people of...   \n",
              "1               Transformed position of fourth point   \n",
              "2  Oh, woe to me; I wish I never took so - and - ...   \n",
              "3  The PS file is to be translated into a PDF fil...   \n",
              "4                   Receiving LDAP search results...   \n",
              "\n",
              "                                                   1  \n",
              "0  और अपनी रहमत से हमें इन काफ़िर लोगों (के नीचे)...  \n",
              "1                     चौथे बिन्दु का रूपांतरित स्थान  \n",
              "2    हाए अफसोस काश मै फला शख्स को अपना दोस्त न बनाता  \n",
              "3  पीएस2पीडीएफ के इस्तेमाल से पीएस फ़ाइल को पीडीए...  \n",
              "4                       LDAP खोज परिणाम पा रहा है...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ddd5a87-cd60-4903-be0d-ce5c6811b2ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and deliver us by Thy mercy from the people of...</td>\n",
              "      <td>और अपनी रहमत से हमें इन काफ़िर लोगों (के नीचे)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Transformed position of fourth point</td>\n",
              "      <td>चौथे बिन्दु का रूपांतरित स्थान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oh, woe to me; I wish I never took so - and - ...</td>\n",
              "      <td>हाए अफसोस काश मै फला शख्स को अपना दोस्त न बनाता</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The PS file is to be translated into a PDF fil...</td>\n",
              "      <td>पीएस2पीडीएफ के इस्तेमाल से पीएस फ़ाइल को पीडीए...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Receiving LDAP search results...</td>\n",
              "      <td>LDAP खोज परिणाम पा रहा है...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ddd5a87-cd60-4903-be0d-ce5c6811b2ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ddd5a87-cd60-4903-be0d-ce5c6811b2ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ddd5a87-cd60-4903-be0d-ce5c6811b2ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# CS779_NLP_COMP/1_MT/input_data/eng_Hindi_data_train.csv\n",
        "df_train = pd.read_csv(file_path+\"eng_Hindi_data_train.csv\", header = None)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4XKjs-VgK2Cz",
        "outputId": "36e52fbb-ff2f-4738-e014-5951f8d0ad33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             English  \\\n",
              "0  and deliver us by Thy mercy from the people of...   \n",
              "1               Transformed position of fourth point   \n",
              "2  Oh, woe to me; I wish I never took so - and - ...   \n",
              "3  The PS file is to be translated into a PDF fil...   \n",
              "4                   Receiving LDAP search results...   \n",
              "\n",
              "                                               Hindi  \n",
              "0  और अपनी रहमत से हमें इन काफ़िर लोगों (के नीचे)...  \n",
              "1                     चौथे बिन्दु का रूपांतरित स्थान  \n",
              "2    हाए अफसोस काश मै फला शख्स को अपना दोस्त न बनाता  \n",
              "3  पीएस2पीडीएफ के इस्तेमाल से पीएस फ़ाइल को पीडीए...  \n",
              "4                       LDAP खोज परिणाम पा रहा है...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d86af55f-5764-4400-8581-3c47b3ca0fde\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and deliver us by Thy mercy from the people of...</td>\n",
              "      <td>और अपनी रहमत से हमें इन काफ़िर लोगों (के नीचे)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Transformed position of fourth point</td>\n",
              "      <td>चौथे बिन्दु का रूपांतरित स्थान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oh, woe to me; I wish I never took so - and - ...</td>\n",
              "      <td>हाए अफसोस काश मै फला शख्स को अपना दोस्त न बनाता</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The PS file is to be translated into a PDF fil...</td>\n",
              "      <td>पीएस2पीडीएफ के इस्तेमाल से पीएस फ़ाइल को पीडीए...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Receiving LDAP search results...</td>\n",
              "      <td>LDAP खोज परिणाम पा रहा है...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d86af55f-5764-4400-8581-3c47b3ca0fde')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d86af55f-5764-4400-8581-3c47b3ca0fde button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d86af55f-5764-4400-8581-3c47b3ca0fde');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_train.columns = ['English', 'Hindi']\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHfvbuKbIt38"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization: \n"
      ],
      "metadata": {
        "id": "ztByjrq4SCZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leVROD_6qz16"
      },
      "outputs": [],
      "source": [
        "# Tokenize text using IndicNLP for Hindi and Spacy for English\n",
        "def preprocess_text_en(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Clean\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    doc = nlp_en(text)\n",
        "    tokens = [token.text for token in doc]\n",
        "    return tokens\n",
        "\n",
        "# using IndicNLP\n",
        "def preprocess_text_hi(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    tokens = []\n",
        "    # Clean\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    sentences= sentence_tokenize.sentence_split(text, lang='hi')\n",
        "    for t_s in sentences:\n",
        "      for t in indic_tokenize.trivial_tokenize(t_s):\n",
        "        tokens.append(t)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Run\n",
        "sample = \"This is Machine Translation model\"\n",
        "print(preprocess_text_en(sample))"
      ],
      "metadata": {
        "id": "aL9YOzhOUASR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/ Valid/ Test Split: "
      ],
      "metadata": {
        "id": "ripJg7_XSItx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeR5XOZPNzdd",
        "outputId": "6889bb8f-0c03-4f36-ed9d-f37f6caf1847"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140000"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUqtG92uPECB"
      },
      "outputs": [],
      "source": [
        "train = df_train[:110000]\n",
        "test = df_train[120000:130000]\n",
        "valid = df_train[130000:]\n",
        "\n",
        "train.to_csv('train.csv', index = False)\n",
        "test.to_csv('test.csv', index = False)\n",
        "valid.to_csv('valid.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate vocabulary\n",
        "https://torchtext.readthedocs.io/en/latest/data.html"
      ],
      "metadata": {
        "id": "feFGnAntSOmD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn8CDZ1ssIju"
      },
      "outputs": [],
      "source": [
        "# Fields for hindi and english languages\n",
        "hindi = Field(tokenize=preprocess_text_hi, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "english = Field(tokenize=preprocess_text_en, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train, validation, test data as TabularDataset\n",
        "train_data = TabularDataset(path='train.csv', format='csv', fields=[('trg', english), ('src', hindi)])\n",
        "valid_data = TabularDataset(path='valid.csv', format='csv', fields=[('trg', english), ('src', hindi)])\n",
        "test_data = TabularDataset(path='test.csv', format='csv', fields=[('trg', english), ('src', hindi)])"
      ],
      "metadata": {
        "id": "RO5QWj59u7nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocabulary\n",
        "hindi.build_vocab(train_data, min_freq=2)\n",
        "english.build_vocab(train_data, min_freq=2)"
      ],
      "metadata": {
        "id": "sLHImB5yu-p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Set batch size\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "ryK59T0WfPRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gmz5adIwbwF"
      },
      "outputs": [],
      "source": [
        "# iterators for train, validation and test data\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), \n",
        "                                                                      batch_size = BATCH_SIZE, sort_within_batch=True, \n",
        "                                                                      sort_key=lambda x: len(x.src), device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbfs74GwmKcq"
      },
      "source": [
        "# 5. Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EncoderLSTM(\n",
        "  <br>\n",
        "  (dropout): Dropout(p=0.3, inplace=False)\n",
        "  <br>\n",
        "  (embedding): Embedding(12271, 500)\n",
        "  <br>\n",
        "  (LSTM): LSTM(500, 1024, num_layers=2, dropout=0.3)\n",
        "  <br>\n",
        ")"
      ],
      "metadata": {
        "id": "7BaHfIRffsVP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vlOtY31y40q"
      },
      "outputs": [],
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "    # Hidden size\n",
        "    self.hidden_size = hidden_size\n",
        "    # Num layers \n",
        "    self.num_layers = num_layers\n",
        "    # Define dropout layer\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "    # Define embedding layer\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    # Define LSTM layer\n",
        "    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # embedded input to LSTM layer\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "    return hidden_state, cell_state"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "encoder_embedding_size = 500\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "encoder_dropout = 0.3\n",
        "encoder_input_size = len(hindi.vocab)\n",
        "# Instantiate EncoderLSTM\n",
        "encoder_lstm = EncoderLSTM(encoder_input_size, encoder_embedding_size,\n",
        "                           hidden_size, num_layers, encoder_dropout).to(device)\n",
        "print(encoder_lstm)"
      ],
      "metadata": {
        "id": "lXrh2Anrf4nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIhD2-OBmVnS"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DecoderLSTM(\n",
        "  <br>\n",
        "  (dropout): Dropout(p=0.3, inplace=False)\n",
        "  <br>\n",
        "  (embedding): Embedding(16523, 500)\n",
        "  <br>\n",
        "  (LSTM): LSTM(500, 1024, num_layers=2, dropout=0.3)\n",
        "  <br>\n",
        "  (fc): Linear(in_features=1024, out_features=16523, bias=True)\n",
        "  <br>\n",
        ")"
      ],
      "metadata": {
        "id": "t-DwpUb8gY3H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnGwwU6p2Zfh"
      },
      "outputs": [],
      "source": [
        "class DecoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
        "    super(DecoderLSTM, self).__init__()\n",
        "    # Hidden size\n",
        "    self.hidden_size = hidden_size\n",
        "    # Num layers\n",
        "    self.num_layers = num_layers\n",
        "    # Output size\n",
        "    self.output_size = output_size\n",
        "    # Dropout layer\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    # Embedding layer\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    # LSTM layer\n",
        "    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n",
        "    # Fully connected layer\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x, hidden_state, cell_state):\n",
        "    x = x.unsqueeze(0)\n",
        "    # Embed input tensor\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    # embedding tensor, previous hidden, cell states through LSTM layer\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
        "    # LSTM output through fully connected layer\n",
        "    predictions = self.fc(outputs)\n",
        "    # Remove added dimension and return predictions\n",
        "    predictions = predictions.squeeze(0)\n",
        "    return predictions, hidden_state, cell_state\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "decoder_embedding_size = 500\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "decoder_dropout = 0.3\n",
        "decoder_input_size = len(english.vocab)\n",
        "output_size = len(english.vocab)\n",
        "# Instantiate DecoderLSTM\n",
        "decoder_lstm = DecoderLSTM(decoder_input_size, decoder_embedding_size,\n",
        "                           hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
        "print(decoder_lstm)"
      ],
      "metadata": {
        "id": "IsnrxFe8gjbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3al--sEzmfmU"
      },
      "source": [
        "# Seq2Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seq2Seq(\n",
        "  <br>\n",
        "  (Encoder_LSTM): EncoderLSTM(\n",
        "    <br>\n",
        "    (dropout): Dropout(p=0.3, \n",
        "    <br>\n",
        "    inplace=False)\n",
        "    <br>\n",
        "    (embedding): Embedding(12271, 500)\n",
        "    <br>\n",
        "    (LSTM): LSTM(500, 1024, num_layers=2, \n",
        "    <br>\n",
        "    dropout=0.3)\n",
        "    <br>\n",
        "  )\n",
        "  <br>\n",
        "  (Decoder_LSTM): DecoderLSTM(\n",
        "    <br>\n",
        "    (dropout): Dropout(p=0.3, \n",
        "    <br>\n",
        "    inplace=False)\n",
        "    <br>\n",
        "    (embedding): Embedding(16523, 500)\n",
        "    <br>\n",
        "    (LSTM): LSTM(500, 1024, num_layers=2,\n",
        "    <br>\n",
        "     dropout=0.3)\n",
        "     <br>\n",
        "    (fc): Linear(in_features=1024, \n",
        "    <br>\n",
        "    out_features=16523, bias=True)\n",
        "    <br>\n",
        "  )\n",
        "  <br>\n",
        ")"
      ],
      "metadata": {
        "id": "psv4EP3movGA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuHGodQe4r9v"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    # initialize the Encoder and Decoder LSTM\n",
        "    self.Encoder_LSTM = Encoder_LSTM\n",
        "    self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "  def forward(self, source, target, tfr=0.5):\n",
        "    # get batch size, target length, and target vocabulary size\n",
        "    batch_size = source.shape[1]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = len(english.vocab)\n",
        "    # outputs tensor with zeros\n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "    hidden_state, cell_state = self.Encoder_LSTM(source)\n",
        "    # initialize first input with the first target token\n",
        "    x = target[0]\n",
        "     # iterate over target sequence\n",
        "    for i in range(1, target_len):\n",
        "      # pass current input, previous hidden, cell states to Decoder LSTM\n",
        "      output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n",
        "      outputs[i] = output\n",
        "      # get index of highest value in output tensor\n",
        "      best_guess = output.argmax(1) \n",
        "      x = target[i] if random.random() < tfr else best_guess \n",
        "    return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 0.001\n",
        "step = 0\n",
        "# Instantiate Seq2Seq model\n",
        "model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
        "# Instantiate optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "h9wg5P0hhQKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtH0Bnq3qFmd"
      },
      "outputs": [],
      "source": [
        "# Set index of <pad> token\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "def translate_sentence(model, sentence, hindi, english, device, max_length=50):\n",
        "    # If input is string\n",
        "    if type(sentence) == str:\n",
        "        tmp = preprocess_text_hi(sentence)\n",
        "        tokens = [token.lower() for token in tmp]\n",
        "    else:\n",
        "        # If input is tokenized,\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add start and end of sequence tokens\n",
        "    tokens.insert(0, hindi.init_token)\n",
        "    tokens.append(hindi.eos_token)\n",
        "\n",
        "    # Convert token sequence to a tensor of indices\n",
        "    text_to_indices = [hindi.vocab.stoi[token] for token in tokens]\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    # Pass input sentence through encoder LSTM\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
        "\n",
        "   # <sos> token\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    # Loop until maximum output length is reached or till <eos> token\n",
        "    for _ in range(max_length):\n",
        "      # previous predicted word as input to decoder LSTM\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "        # input word and previous hidden and cell states through decoder LSTM\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell)\n",
        "            # index of the word with highest probability\n",
        "            best_guess = output.argmax(1).item()\n",
        "        # predicted word to output sequence\n",
        "        outputs.append(best_guess)\n",
        "        # <eos> token is predicted, break loop\n",
        "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "    # output sequence of indices to a sequence of tokens\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "    # excluding the <sos> token\n",
        "    return translated_sentence[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6VnFyCnNlTz"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M79z-3BfN51i",
        "outputId": "22ad260e-f017-4b32-9de8-46dc26d204aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 11 14:39:57 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0    34W /  70W |   1459MiB / 15360MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4jLBPRD9osT",
        "outputId": "03a64dac-2fe9-4f92-839d-94cbb73fff5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch - 1 / 12\n",
            "Translated example sentence 1: \n",
            " ['scuttled', 'felicitous', 'influence', 'extremes', 'lashes', 'bookmarks', 'influence', 'extremes', 'bookmarks', 'desperate', 'extremes', 'desperate', 'prostitute', 'things', 'things', 'things', 'fame', 'fame', 'draught', 'consultation', 'center', 'swarming', 'swarming', 'spurred', 'uppressed', 'tus', 'seer', 'lights', 'seer', 'enabledgt', 'miasma', 'worldly', 'wing', 'knows', 'knows', 'pleasantry', 'pleasantry', 'pleasantry', 'encourage', 'pleasantry', 'pleasantry', 'pleasantry', 'pleasantry', 'pleasantry', 'pleasantry', 'pleasantry', 'pleasantry', 'pleasantry', 'pleasantry', 'pleasantry']\n",
            "saving\n",
            "\n",
            "Epoch_Loss - 3.662508010864258\n",
            "\n",
            "Epoch - 2 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', 'in', 'in', '<unk>', '<eos>']\n",
            "Epoch_Loss - 3.6439239978790283\n",
            "\n",
            "Epoch - 3 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', 'the', 'in', '<unk>', '<eos>']\n",
            "Epoch_Loss - 2.9913182258605957\n",
            "\n",
            "Epoch - 4 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', 'in', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 1.8543459177017212\n",
            "\n",
            "Epoch - 5 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', 'a', 'in', 'in', 'a', 'game', '<eos>']\n",
            "Epoch_Loss - 1.94550621509552\n",
            "\n",
            "Epoch - 6 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', 'in', 'a', 'game', '<eos>']\n",
            "Epoch_Loss - 4.591447830200195\n",
            "\n",
            "Epoch - 7 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', 'in', 'the', 'game', 'game', '<eos>']\n",
            "Epoch_Loss - 2.565458059310913\n",
            "\n",
            "Epoch - 8 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', ' ', 'link', 'in', 'konqueror', '<eos>']\n",
            "Epoch_Loss - 0.7997756600379944\n",
            "\n",
            "Epoch - 9 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', ' ', 'link', 'in', 'konqueror', '<eos>']\n",
            "Epoch_Loss - 2.8670849800109863\n",
            "\n",
            "Epoch - 10 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', 'in', 'session', 'in', 'konqueror', '<eos>']\n",
            "Epoch_Loss - 2.113736629486084\n",
            "\n",
            "Epoch - 11 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', 'in', 'session', 'in', '<eos>']\n",
            "Epoch_Loss - 3.544461250305176\n",
            "\n",
            "Epoch - 12 / 12\n",
            "Translated example sentence 1: \n",
            " ['open', 'a', 'kde', 'game', 'in', '<eos>']\n",
            "Epoch_Loss - 1.1119394302368164\n",
            "\n",
            "37.15133630934672\n"
          ]
        }
      ],
      "source": [
        "epoch_loss = 0.0\n",
        "num_epochs = 12\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "  model.eval()\n",
        "  model.train(True)\n",
        "  for batch_idx, batch in enumerate(train_iterator):\n",
        "    input = batch.src.to(device)\n",
        "    target = batch.trg.to(device)\n",
        "\n",
        "    # Pass the input and target for model's forward method\n",
        "    output = model(input, target)\n",
        "    output = output[1:].reshape(-1, output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "\n",
        "    # Clear gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Calculate loss \n",
        "    loss = criterion(output, target)\n",
        "    # back-propagation\n",
        "    loss.backward()\n",
        "    # Cut gradient value if > 1\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "    step += 1\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  print(\"Epoch_Loss - {}\".format(loss.item()))\n",
        "  print()\n",
        "  \n",
        "print(epoch_loss / len(train_iterator))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5Bx_wZ4LvmS"
      },
      "outputs": [],
      "source": [
        "# Path to save model\n",
        "model_path = \"/model_12.pt\"\n",
        "# Save model\n",
        "torch.save(model.state_dict(), file_path + model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olt0QP48Uno1"
      },
      "source": [
        "#Load Pretrained model for furthur epoch training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO9-NF_8MIga",
        "outputId": "e9b93c14-2374-4a68-c6fe-536748043449"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Define path where saved model is located\n",
        "model_path = \"model_40.pt\"\n",
        "\n",
        "# Load saved model\n",
        "model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
        "model.load_state_dict(torch.load(file_path+model_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt8G5W4FMwZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc1c72d-5898-46ca-bbbe-4d14433e4137"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and',\n",
              " 'follow',\n",
              " 'the',\n",
              " 'best',\n",
              " 'of',\n",
              " 'the',\n",
              " 'has',\n",
              " 'been',\n",
              " 'sent',\n",
              " 'down',\n",
              " 'to',\n",
              " 'you',\n",
              " 'from',\n",
              " 'your',\n",
              " 'lord',\n",
              " 'before',\n",
              " 'the',\n",
              " 'torment',\n",
              " 'overtakes',\n",
              " 'you',\n",
              " 'suddenly',\n",
              " 'while',\n",
              " 'you',\n",
              " 'are',\n",
              " 'unaware',\n",
              " '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "hd_st = \"और अनुसर्ण करो उस सर्वोत्तम चीज़ का जो तुम्हारे रब की ओर से अवतरित हुई है, इससे पहले कि तुम पर अचानक यातना आ जाए और तुम्हें पता भी न हो। \"\n",
        "ans = translate_sentence(model, hd_st, hindi, english, device, max_length=50)\n",
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KDScWiFNF5N",
        "outputId": "8ab7b0f3-6399-4455-dcb6-33c4aff70d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "and follow the best of the has been sent down to you from your lord before the torment overtakes you suddenly while you are unaware\n"
          ]
        }
      ],
      "source": [
        "sentence = ' '.join(ans)\n",
        "print(sentence[:-6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Y2zi6JNizj"
      },
      "source": [
        "##Run model for further epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5rx6nbaNm4x",
        "outputId": "18000341-2b88-45ca-f278-3e786f7e476d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 41 / 50\n",
            "Translated example sentence 1: \n",
            " ['open', 'the', 'in', 'session', 'in', '<eos>']\n",
            "saving\n",
            "\n",
            "Epoch_Loss - 0.6145027875900269\n",
            "\n",
            "Epoch - 42 / 50\n",
            "Translated example sentence 1: \n",
            " ['run', 'the', 'in', 'irresistible', 'session', '<eos>']\n",
            "Epoch_Loss - 0.7174165844917297\n",
            "\n",
            "Epoch - 43 / 50\n",
            "Translated example sentence 1: \n",
            " ['open', 'the', 'upper', 'find', 'conflict', 'in', 'a', 'running', 'browser', '<eos>']\n",
            "Epoch_Loss - 2.4101617336273193\n",
            "\n",
            "Epoch - 44 / 50\n",
            "Translated example sentence 1: \n",
            " ['open', 'the', 'upper', 'link', 'in', 'a', 'window', '<eos>']\n",
            "Epoch_Loss - 2.1067566871643066\n",
            "\n",
            "Epoch - 45 / 50\n",
            "Translated example sentence 1: \n",
            " ['open', 'the', 'in', 'session', 'in', 'tabs', '<eos>']\n",
            "Epoch_Loss - 3.730891466140747\n",
            "\n",
            "Epoch - 46 / 50\n",
            "Translated example sentence 1: \n",
            " ['open', 'the', 'last', 'session', 'in', 'the', 'mode', '<eos>']\n",
            "Epoch_Loss - 1.1555683612823486\n",
            "\n",
            "Epoch - 47 / 50\n",
            "Translated example sentence 1: \n",
            " ['open', '<unk>', 'in', 'in', 'a', '<eos>']\n",
            "Epoch_Loss - 1.1219122409820557\n",
            "\n",
            "Epoch - 48 / 50\n",
            "Translated example sentence 1: \n",
            " ['open', 'a', 'in', 'in', 'a', '<eos>']\n",
            "Epoch_Loss - 1.1841175556182861\n",
            "\n",
            "Epoch - 49 / 50\n",
            "Translated example sentence 1: \n",
            " ['open', ' ', 'in', 'in', 'session', '<eos>']\n"
          ]
        }
      ],
      "source": [
        "# Saved Model epoch\n",
        "prev_epoch = 40\n",
        "# New epoch\n",
        "epoch_loss = 0.0\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Epoch - {} / {}\".format(epoch+1+prev_epoch, num_epochs+prev_epoch))\n",
        "  model.eval()\n",
        "  model.train(True)\n",
        "  for batch_idx, batch in enumerate(train_iterator):\n",
        "    input = batch.src.to(device)\n",
        "    target = batch.trg.to(device)\n",
        "    # Pass the input and target for model's forward method\n",
        "    output = model(input, target)\n",
        "    output = output[1:].reshape(-1, output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "\n",
        "    # Clear gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Calculate loss \n",
        "    loss = criterion(output, target)\n",
        "    # back-propagation\n",
        "    loss.backward()\n",
        "    # Cut gradient value if > 1\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "    step += 1\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  print(\"Epoch_Loss - {}\".format(loss.item()))\n",
        "  print()\n",
        "  \n",
        "print(epoch_loss / len(train_iterator))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fUlHC4vPeBU"
      },
      "source": [
        "###Again Check accuracy after retraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TicudyZ4QBGs"
      },
      "source": [
        "Hindi_sentence = \"और अनुसर्ण करो उस सर्वोत्तम चीज़ का जो तुम्हारे रब की ओर से अवतरित हुई है, इससे पहले कि तुम पर अचानक यातना आ जाए और तुम्हें पता भी न हो। \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn8T7ZgfP1vd"
      },
      "source": [
        "Prev epoch output(Eng sentence): \"and follow the best of what has been sent down to you from your lord and your lord is not negligent of you\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djR4akjrNm-j"
      },
      "outputs": [],
      "source": [
        "hd_st = \"और अनुसर्ण करो उस सर्वोत्तम चीज़ का जो तुम्हारे रब की ओर से अवतरित हुई है, इससे पहले कि तुम पर अचानक यातना आ जाए और तुम्हें पता भी न हो। \"\n",
        "ans = translate_sentence(model, hd_st, hindi, english, device, max_length=50)\n",
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTtuHYowPuoR"
      },
      "outputs": [],
      "source": [
        "sentence = ' '.join(ans)\n",
        "print(sentence[:-6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUC1y98nULhA"
      },
      "source": [
        "If accuracy is great Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IapF6bGAURB5"
      },
      "outputs": [],
      "source": [
        "# Define path to save model\n",
        "model_path = \"/model_50.pt\"\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), file_path + model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6BP_0KiU7tE"
      },
      "source": [
        "#Save Test Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCDlprGHU5W0"
      },
      "outputs": [],
      "source": [
        "#/content/drive/MyDrive/CS779_NLP_COMP/1_MT/input_data/eng_Hindi_data_dev_X.csv\n",
        "df_test = pd.read_csv(file_path+\"eng_Hindi_data_dev_X.csv\", header = None)\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV_AGpzuWRen"
      },
      "outputs": [],
      "source": [
        "df_test.columns = ['Hindi']\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSpZSu_6WjdE"
      },
      "outputs": [],
      "source": [
        "tot = len(df_test['Hindi'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1oAg_MpWPZY"
      },
      "outputs": [],
      "source": [
        "ans = translate_sentence(model, df_test['Hindi'][0], hindi, english, device, max_length=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW1JkRhrXElE"
      },
      "outputs": [],
      "source": [
        "sentence = ' '.join(ans)\n",
        "print(sentence[:-6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RJyBQcMXkfx"
      },
      "outputs": [],
      "source": [
        "trans_test = []\n",
        "cnt = 0\n",
        "for i in range(tot):\n",
        "  cnt = cnt + 1\n",
        "  ans = translate_sentence(model, df_test['Hindi'][i], hindi, english, device, max_length=50)\n",
        "  sentence = ' '.join(ans)\n",
        "  # print(sentence[:-6])\n",
        "  trans_test.append(sentence[:-6])\n",
        "  print(cnt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S61lGGUwQUxM"
      },
      "source": [
        "Save with string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5Z4Z9pgYW2F"
      },
      "outputs": [],
      "source": [
        "y_dev_pred_str = '\\n'.join(map(str, [pred for pred in trans_test]))\n",
        "\n",
        "with open('answer.txt', 'w', encoding='utf-8') as file:\n",
        "    file.write(y_dev_pred_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg1e2rOnJv2E"
      },
      "outputs": [],
      "source": [
        "y_dev_pred_str[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0KSI-tPQc1i"
      },
      "source": [
        "Save with List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiQvXy3vKWKA",
        "outputId": "969c7fbc-6ea6-466a-bf4e-81c39d70466c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "len(trans_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvT2gTyRKcBR",
        "outputId": "c1ac8fe0-942a-4fdf-de7d-de7625aa121e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and follow the best of what we have sent down to you from your lord before you suddenly it comes on you suddenly while you perceive not',\n",
              " 'and thereafter a caravan of his people and he water to drawer and he he and his bucket and his to his and luck and he had given him and he merchandise which he had been given to him and he is an enemy to him',\n",
              " 'whoever brings a good deed will receive better than itand and worth and such will be safe from him demand',\n",
              " '   square <unk>']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "trans_test[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM__9_6dKv7u"
      },
      "outputs": [],
      "source": [
        "with open('my_list.txt', 'w', encoding='utf-8') as file:\n",
        "    for item in trans_test:\n",
        "        file.write(\"%s\\n\" % item)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "<br>\n",
        "https://drive.google.com/file/d/1D8dZAC3QAtAuPKfSb0qmBm1NxPcv4vUq/view\n",
        "<br>\n",
        "https://torchtext.readthedocs.io/en/latest/data.html"
      ],
      "metadata": {
        "id": "823RzzEtw8MI"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}